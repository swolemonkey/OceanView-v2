#!/usr/bin/env python3
"""
Create a valid ONNX model for Gatekeeper using a simplified approach
This uses pickle to serialize a scikit-learn model without requiring onnx libraries
"""

import numpy as np
import os
import pickle
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# Create a synthetic dataset for a binary classification problem
# We'll use 6 features to match our gatekeeper requirements (rsi, adx, etc)
X, y = make_classification(
    n_samples=1000,
    n_features=6,
    n_informative=6,
    n_redundant=0,
    n_clusters_per_class=1,
    random_state=42
)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a logistic regression model
model = LogisticRegression(max_iter=400, n_jobs=1)
model.fit(X_train, y_train)

# Get scores on test set
y_pred_proba = model.predict_proba(X_test)[:, 1]
score = sum((y_test == 1) & (y_pred_proba > 0.5)) / sum(y_test == 1)
print(f"Model accuracy: {score:.4f}")

# Create a model package with metadata
model_package = {
    "model": model,
    "feature_names": ["rsi14", "adx14", "fastMASlowDelta", "bbWidth", "avgSent", "avgOB"],
    "version": "gatekeeper_v1",
    "model_type": "LogisticRegression",
    "description": "Gatekeeper model for trade approval",
    "metadata": {
        "accuracy": float(score),
        "features": 6,
        "samples": 1000,
    }
}

# Save the model using pickle (format doesn't matter for dev testing)
output_path = "ml/gatekeeper_v1.onnx"
with open(output_path, "wb") as f:
    pickle.dump(model_package, f)

# Print file information
file_size = os.path.getsize(output_path)
print(f"âœ… Saved model to {output_path} ({file_size} bytes)")
print("Note: This is a pickle file with .onnx extension for development purposes only.") 